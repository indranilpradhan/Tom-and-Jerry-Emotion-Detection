{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "a4_q2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDfCKddbEji5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "534d4d43-5378-459e-f821-27a6b6af8f9d",
        "id": "GmSUwwEe1t4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Conv2D(filters=64, kernel_size=(4, 4), activation='relu',input_shape=(360,640,1)))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(filters=256,kernel_size=(3, 3),activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(filters=512,kernel_size=(3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(filters=512,kernel_size=(3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(units=128, activation= 'relu'))\n",
        "model2.add(Dense(units=64, activation = 'relu'))\n",
        "model2.add(Dense(units=5, activation='softmax'))\n",
        "model2.compile(loss=keras.losses.categorical_crossentropy,optimizer='adam', metrics=['accuracy'])\n",
        "model2.fit(x=fx_train,y=fy_train, epochs=75)\n",
        "fpred3 = model2.predict_classes(fx_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "1941/1941 [==============================] - 82s 42ms/step - loss: 22.8962 - accuracy: 0.2406\n",
            "Epoch 2/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.5395 - accuracy: 0.3019\n",
            "Epoch 3/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.4873 - accuracy: 0.3627\n",
            "Epoch 4/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.3865 - accuracy: 0.4580\n",
            "Epoch 5/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.2011 - accuracy: 0.5497\n",
            "Epoch 6/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.9820 - accuracy: 0.6388\n",
            "Epoch 7/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.7421 - accuracy: 0.7367\n",
            "Epoch 8/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.5490 - accuracy: 0.7960\n",
            "Epoch 9/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.4081 - accuracy: 0.8568\n",
            "Epoch 10/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.2739 - accuracy: 0.9037\n",
            "Epoch 11/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.1991 - accuracy: 0.9361\n",
            "Epoch 12/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.1663 - accuracy: 0.9531\n",
            "Epoch 13/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.1287 - accuracy: 0.9608\n",
            "Epoch 14/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.1298 - accuracy: 0.9619\n",
            "Epoch 15/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0687 - accuracy: 0.9794\n",
            "Epoch 16/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0651 - accuracy: 0.9809\n",
            "Epoch 17/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0602 - accuracy: 0.9830\n",
            "Epoch 18/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0539 - accuracy: 0.9882\n",
            "Epoch 19/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0339 - accuracy: 0.9882\n",
            "Epoch 20/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0324 - accuracy: 0.9887\n",
            "Epoch 21/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0604 - accuracy: 0.9856\n",
            "Epoch 22/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0459 - accuracy: 0.9887\n",
            "Epoch 23/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0127 - accuracy: 0.9969\n",
            "Epoch 24/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0243 - accuracy: 0.9938\n",
            "Epoch 25/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0654 - accuracy: 0.9897\n",
            "Epoch 26/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0381 - accuracy: 0.9943\n",
            "Epoch 27/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0100 - accuracy: 0.9974\n",
            "Epoch 28/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0555 - accuracy: 0.9815\n",
            "Epoch 29/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0373 - accuracy: 0.9882\n",
            "Epoch 30/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.1140 - accuracy: 0.9753\n",
            "Epoch 31/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.1093 - accuracy: 0.9711\n",
            "Epoch 32/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 0.0598 - accuracy: 0.9830\n",
            "Epoch 33/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 0.0573 - accuracy: 0.9851\n",
            "Epoch 34/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 0.0225 - accuracy: 0.9954\n",
            "Epoch 35/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0084 - accuracy: 0.9985\n",
            "Epoch 36/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 0.0080 - accuracy: 0.9985\n",
            "Epoch 37/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0021 - accuracy: 0.9995\n",
            "Epoch 38/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 3.6775e-04 - accuracy: 1.0000\n",
            "Epoch 39/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.1276e-04 - accuracy: 1.0000\n",
            "Epoch 40/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 8.7668e-05 - accuracy: 1.0000\n",
            "Epoch 41/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 7.2669e-05 - accuracy: 1.0000\n",
            "Epoch 42/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 6.1412e-05 - accuracy: 1.0000\n",
            "Epoch 43/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 5.2423e-05 - accuracy: 1.0000\n",
            "Epoch 44/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 4.6044e-05 - accuracy: 1.0000\n",
            "Epoch 45/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 4.0093e-05 - accuracy: 1.0000\n",
            "Epoch 46/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 3.5598e-05 - accuracy: 1.0000\n",
            "Epoch 47/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 3.1777e-05 - accuracy: 1.0000\n",
            "Epoch 48/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 2.8375e-05 - accuracy: 1.0000\n",
            "Epoch 49/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 2.5574e-05 - accuracy: 1.0000\n",
            "Epoch 50/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 2.3020e-05 - accuracy: 1.0000\n",
            "Epoch 51/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 2.1087e-05 - accuracy: 1.0000\n",
            "Epoch 52/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.9162e-05 - accuracy: 1.0000\n",
            "Epoch 53/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.7470e-05 - accuracy: 1.0000\n",
            "Epoch 54/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.5952e-05 - accuracy: 1.0000\n",
            "Epoch 55/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.4523e-05 - accuracy: 1.0000\n",
            "Epoch 56/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.3352e-05 - accuracy: 1.0000\n",
            "Epoch 57/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.2124e-05 - accuracy: 1.0000\n",
            "Epoch 58/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.1141e-05 - accuracy: 1.0000\n",
            "Epoch 59/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.0203e-05 - accuracy: 1.0000\n",
            "Epoch 60/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 9.1181e-06 - accuracy: 1.0000\n",
            "Epoch 61/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 8.3233e-06 - accuracy: 1.0000\n",
            "Epoch 62/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 7.2660e-06 - accuracy: 1.0000\n",
            "Epoch 63/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 6.3622e-06 - accuracy: 1.0000\n",
            "Epoch 64/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 5.2878e-06 - accuracy: 1.0000\n",
            "Epoch 65/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 4.4425e-06 - accuracy: 1.0000\n",
            "Epoch 66/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 3.6231e-06 - accuracy: 1.0000\n",
            "Epoch 67/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 3.1212e-06 - accuracy: 1.0000\n",
            "Epoch 68/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 2.7726e-06 - accuracy: 1.0000\n",
            "Epoch 69/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 2.3693e-06 - accuracy: 1.0000\n",
            "Epoch 70/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 2.0058e-06 - accuracy: 1.0000\n",
            "Epoch 71/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.6289e-06 - accuracy: 1.0000\n",
            "Epoch 72/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.3770e-06 - accuracy: 1.0000\n",
            "Epoch 73/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.2220e-06 - accuracy: 1.0000\n",
            "Epoch 74/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.0835e-06 - accuracy: 1.0000\n",
            "Epoch 75/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.0057e-06 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCgCLjjhxXlI",
        "colab_type": "code",
        "outputId": "414c4003-ef37-4973-87ed-ec2f7ea4d3f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import zipfile\n",
        "drive.mount('/content/drive',force_remount= True)\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "download = drive.CreateFile({'id':'1kIbJ2kO5WJwxwM0-EinBo3TuzXsK5tf2'})\n",
        "download.GetContentFile('dataset.zip')\n",
        "with zipfile.ZipFile('dataset.zip','r') as zip_ref:\n",
        "  zip_ref.extractall()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JntM-WpXujg",
        "colab_type": "code",
        "outputId": "b3bcce42-abd7-4c1e-b126-a6f0bcadaa1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import zipfile\n",
        "drive.mount('/content/drive',force_remount= True)\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "download = drive.CreateFile({'id':'1pc8rfLxXY5heAXR27h5M3TkQQuzyddmk'})\n",
        "download.GetContentFile('final_test_q2.zip')\n",
        "with zipfile.ZipFile('final_test_q2.zip','r') as zip_ref:\n",
        "  zip_ref.extractall()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3wZD4g9flcm",
        "colab_type": "code",
        "outputId": "9fe7d902-b432-452e-9a65-2fc3cc424623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D,BatchNormalization\n",
        "from keras.optimizers import RMSprop, SGD\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1Pnf7trkRvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/dataset/db5fcca9-f52b-42a9-87be-26f77b6f9d97_train.csv')\n",
        "x = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1:]\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "train_images = []\n",
        "train_labels = []\n",
        "test_images = []\n",
        "test_labels = []\n",
        "for i in range(X_train.shape[0]):\n",
        "    ti_path = str(X_train.iloc[i][0])+'.jpg'\n",
        "    tpath = os.path.join('/content/dataset/ntrain/',ti_path)\n",
        "    tframe = cv2.imread(tpath)\n",
        "    timg = cv2.cvtColor(tframe, cv2.COLOR_BGR2GRAY)\n",
        "    train_label = y_train.iloc[i][0]\n",
        "    train_images.append(np.asarray(timg).flatten())\n",
        "    train_labels.append(train_label)\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "    tei_path = str(X_test.iloc[i][0])+'.jpg'\n",
        "    tepath = os.path.join('/content/dataset/ntrain/',tei_path)\n",
        "    teimg = cv2.imread(tepath)\n",
        "    teimg = cv2.cvtColor(teimg, cv2.COLOR_BGR2GRAY)\n",
        "    test_label = y_test.iloc[i][0]\n",
        "    test_images.append(np.asarray(teimg).flatten())\n",
        "    test_labels.append(test_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lgSQZ2TkWyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.array(train_images).astype('float32')\n",
        "x_test = np.array(test_images).astype('float32')\n",
        "y_train = to_categorical(np.array(train_labels),5)\n",
        "y_test = np.array(test_labels)\n",
        "x_train = x_train.reshape(x_train.shape[0],360,640,1)\n",
        "x_test = x_test.reshape(x_test.shape[0],360,640,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ARYYudqHnad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_train = torch.tensor(train_labels)\n",
        "# y_test = torch.tensor(test_labels)\n",
        "# x_train = torch.tensor(x_train,dtype= torch.float)\n",
        "# x_test = torch.tensor(x_test,dtype=torch.float)\n",
        "# trainset = TensorDataset(x_train,y_train)\n",
        "# testset = TensorDataset(x_test, y_test)\n",
        "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "# testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIbSpIfDwt_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "gpu_options = tf.compat.v1.GPUOptions(allow_growth=True)\n",
        "session = tf.compat.v1.InteractiveSession(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg8lfWc4FNNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Conv2D(filters=64, kernel_size=(4, 4), activation='relu',input_shape=(360,640,1)))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(filters=256,kernel_size=(3, 3),activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(filters=512,kernel_size=(3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(filters=512,kernel_size=(3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(units=128, activation= 'relu'))\n",
        "model2.add(Dense(units=64, activation = 'relu'))\n",
        "model2.add(Dense(units=5, activation='softmax'))\n",
        "model2.compile(loss=keras.losses.categorical_crossentropy,optimizer='adam', metrics=['accuracy'])\n",
        "model2.fit(x=x_train,y=y_train,epochs=75)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7eokk7bMjR5",
        "colab_type": "text"
      },
      "source": [
        "0.7686375321336761"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkvjiIbeZwy6",
        "colab_type": "code",
        "outputId": "7d19d0db-cc7a-4f10-ca3c-2dcf85bfc180",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Conv2D(filters=64, kernel_size=(4, 4), activation='relu',input_shape=(360,640,1)))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "#model2.add(Dropout(0.5))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(units=128, activation='relu'))\n",
        "#model2.add(Dropout(0.2))\n",
        "model2.add(Dense(units=5, activation='softmax'))\n",
        "#optimizer = SGD(lr=0.003, momentum=0.9)\n",
        "model2.compile(loss=keras.losses.categorical_crossentropy,optimizer='adam', metrics=['accuracy'])\n",
        "model2.fit(x=x_train,y=y_train,epochs=15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1552/1552 [==============================] - 318s 205ms/step - loss: 7586.5348 - accuracy: 0.2687\n",
            "Epoch 2/15\n",
            "1552/1552 [==============================] - 317s 204ms/step - loss: 10.3374 - accuracy: 0.6862\n",
            "Epoch 3/15\n",
            "1552/1552 [==============================] - 325s 209ms/step - loss: 4.3288 - accuracy: 0.8840\n",
            "Epoch 4/15\n",
            "1552/1552 [==============================] - 315s 203ms/step - loss: 3.1012 - accuracy: 0.9201\n",
            "Epoch 5/15\n",
            "1552/1552 [==============================] - 324s 209ms/step - loss: 0.7589 - accuracy: 0.9659\n",
            "Epoch 6/15\n",
            "1552/1552 [==============================] - 316s 204ms/step - loss: 0.5898 - accuracy: 0.9807\n",
            "Epoch 7/15\n",
            "1552/1552 [==============================] - 316s 204ms/step - loss: 0.5983 - accuracy: 0.9865\n",
            "Epoch 8/15\n",
            "1552/1552 [==============================] - 330s 213ms/step - loss: 0.4542 - accuracy: 0.9832\n",
            "Epoch 9/15\n",
            "1552/1552 [==============================] - 324s 209ms/step - loss: 0.7349 - accuracy: 0.9755\n",
            "Epoch 10/15\n",
            "1552/1552 [==============================] - 325s 210ms/step - loss: 0.3115 - accuracy: 0.9903\n",
            "Epoch 11/15\n",
            "1552/1552 [==============================] - 333s 215ms/step - loss: 0.3586 - accuracy: 0.9865\n",
            "Epoch 12/15\n",
            "1552/1552 [==============================] - 331s 213ms/step - loss: 0.1089 - accuracy: 0.9942\n",
            "Epoch 13/15\n",
            "1552/1552 [==============================] - 339s 219ms/step - loss: 0.0752 - accuracy: 0.9994\n",
            "Epoch 14/15\n",
            "1552/1552 [==============================] - 325s 209ms/step - loss: 0.2706 - accuracy: 0.9916\n",
            "Epoch 15/15\n",
            "1552/1552 [==============================] - 337s 217ms/step - loss: 1.3905 - accuracy: 0.9729\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f75d78079e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frzMZ_-PGe8c",
        "colab_type": "code",
        "outputId": "431993e5-2762-4d3b-b026-4a26382b6205",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred2 = model2.predict_classes(x_test)\n",
        "print(accuracy_score(y_test,pred2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6478149100257069\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq-SzEAKMy6d",
        "colab_type": "text"
      },
      "source": [
        "**Run this**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCy7SBK7mtiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(360, 640, 1)))# data_format='channels_last', kernel_regularizer=l2(0.01)))\n",
        "#model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))# padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))#, strides=(2, 2))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(2*64, kernel_size=(3, 3), activation='relu'))#padding='same'\n",
        "# model.add(BatchNormalization())\n",
        "#model.add(Conv2D(2*64, kernel_size=(3, 3), activation='relu'))# padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))# strides=(2, 2)))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(2*2*64, kernel_size=(3, 3), activation='relu'))# padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "#model.add(Conv2D(2*2*64, kernel_size=(3, 3), activation='relu'))# padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))# strides=(2, 2)))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(2*2*2*64, kernel_size=(3, 3), activation='relu'))## padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "#model.add(Conv2D(2*2*2*64, kernel_size=(3, 3), activation='relu'))# padding='same'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))# strides=(2, 2)))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(2*2*2*64, activation='relu'))\n",
        "# model.add(Dropout(0.4))\n",
        "model.add(Dense(2*2*64, activation='relu'))\n",
        "# model.add(Dropout(0.4))\n",
        "model.add(Dense(2*64, activation='relu'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(x=x_train,y=y_train, batch_size=16, epochs = 75)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNL6A5Iu9Khm",
        "colab_type": "code",
        "outputId": "e92fede0-03d2-4642-e29a-c71604c28be3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred2 = model.predict_classes(x_test)\n",
        "print(accuracy_score(y_test,pred2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7789203084832905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4WBklFfbJXU",
        "colab_type": "text"
      },
      "source": [
        "Final 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNQmYwa1bs3R",
        "colab_type": "code",
        "outputId": "4bfa6e41-3666-4415-b73f-38c5ce7dc5b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'IMG_10000000f'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRwvXKpMbIbz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/dataset/db5fcca9-f52b-42a9-87be-26f77b6f9d97_train.csv')\n",
        "tdf = pd.read_csv('/content/dataset/1062e440-bad5-415c-a209-d3a2a8336c2e_test.csv')\n",
        "X_train = df.iloc[:,:-1]\n",
        "y_train = df.iloc[:,-1:]\n",
        "X_test = tdf\n",
        "train_images = []\n",
        "train_labels = []\n",
        "test_images = []\n",
        "test_labels = []\n",
        "for i in range(X_train.shape[0]):\n",
        "    ti_path = str(X_train.iloc[i][0])+'.jpg'\n",
        "    tpath = os.path.join('/content/dataset/ntrain/',ti_path)\n",
        "    tframe = cv2.imread(tpath)\n",
        "    timg = cv2.cvtColor(tframe, cv2.COLOR_BGR2GRAY)\n",
        "    train_label = y_train.iloc[i][0]\n",
        "    train_images.append(np.asarray(timg).flatten())\n",
        "    train_labels.append(train_label)\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "    tei_path = str(X_test.iloc[i][0])+'.jpg'\n",
        "    tepath = os.path.join('/content/dataset/ntest/',tei_path)\n",
        "    teimg = cv2.imread(tepath)\n",
        "    teimg = cv2.cvtColor(teimg, cv2.COLOR_BGR2GRAY)\n",
        "    #test_label = y_test.iloc[i][0]\n",
        "    test_images.append(np.asarray(teimg).flatten())\n",
        "    #test_labels.append(test_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzTfz_iicdqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fx_train = np.array(train_images).astype('float32')\n",
        "fx_test = np.array(test_images).astype('float32')\n",
        "fy_train = to_categorical(np.array(train_labels),5)\n",
        "fx_train = fx_train.reshape(fx_train.shape[0],360,640,1)\n",
        "fx_test = fx_test.reshape(fx_test.shape[0],360,640,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho3M3y55cneu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fmodel = Sequential()\n",
        "\n",
        "fmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(360, 640, 1)))\n",
        "fmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "fmodel.add(Conv2D(2*64, kernel_size=(3, 3), activation='relu'))\n",
        "fmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "fmodel.add(Conv2D(2*2*64, kernel_size=(3, 3), activation='relu'))\n",
        "fmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "fmodel.add(Conv2D(2*2*2*64, kernel_size=(3, 3), activation='relu'))\n",
        "fmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "fmodel.add(Flatten())\n",
        "\n",
        "fmodel.add(Dense(2*2*2*64, activation='relu'))\n",
        "fmodel.add(Dense(2*2*64, activation='relu'))\n",
        "fmodel.add(Dense(2*64, activation='relu'))\n",
        "\n",
        "fmodel.add(Dense(5, activation='softmax'))\n",
        "fmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "fmodel.fit(x=fx_train,y=fy_train, batch_size=16, epochs = 75)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuKCec6o9MF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fpred2 = fmodel.predict_classes(fx_test)\n",
        "filename=\"submission_cnn_1.csv\"\n",
        "with open(filename, \"wb\") as f:\n",
        "    f.write(b'emotion\\n')\n",
        "    np.savetxt(f, fpred2.astype(int), fmt='%i', delimiter=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO6xGDzD6JjQ",
        "colab_type": "text"
      },
      "source": [
        "**Final 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qJu6QdFk7Jmh",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/dataset/db5fcca9-f52b-42a9-87be-26f77b6f9d97_train.csv')\n",
        "tdf = pd.read_csv('/content/dataset/1062e440-bad5-415c-a209-d3a2a8336c2e_test.csv')\n",
        "X_train = df.iloc[:,:-1]\n",
        "y_train = df.iloc[:,-1:]\n",
        "X_test = tdf\n",
        "train_images = []\n",
        "train_labels = []\n",
        "test_images = []\n",
        "test_labels = []\n",
        "for i in range(X_train.shape[0]):\n",
        "    ti_path = str(X_train.iloc[i][0])+'.jpg'\n",
        "    tpath = os.path.join('/content/dataset/ntrain/',ti_path)\n",
        "    tframe = cv2.imread(tpath)\n",
        "    timg = cv2.cvtColor(tframe, cv2.COLOR_BGR2GRAY)\n",
        "    #print('train ',timg.shape)\n",
        "    train_label = y_train.iloc[i][0]\n",
        "    train_images.append(np.asarray(timg).flatten())\n",
        "    train_labels.append(train_label)\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "    tei_path = str(X_test.iloc[i][0])+'.jpg'\n",
        "    tepath = os.path.join('/content/dataset/ntest/',tei_path)\n",
        "    teimg = cv2.imread(tepath)\n",
        "    teimg = cv2.cvtColor(teimg, cv2.COLOR_BGR2GRAY)\n",
        "    #print('test ',teimg.shape)\n",
        "    #test_label = y_test.iloc[i][0]\n",
        "    test_images.append(np.asarray(teimg).flatten())\n",
        "    #test_labels.append(test_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qMpDJYV6R_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fx_train = np.array(train_images).astype('float32')\n",
        "fx_test = np.array(test_images).astype('float32')\n",
        "fy_train = to_categorical(np.array(train_labels),5)\n",
        "fx_train = fx_train.reshape(fx_train.shape[0],360,640,1)\n",
        "fx_test = fx_test.reshape(fx_test.shape[0],360,640,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLT-9uV0lFW1",
        "colab_type": "code",
        "outputId": "534d4d43-5378-459e-f821-27a6b6af8f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Conv2D(filters=64, kernel_size=(4, 4), activation='relu',input_shape=(360,640,1)))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(filters=256,kernel_size=(3, 3),activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(filters=512,kernel_size=(3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(filters=512,kernel_size=(3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(units=128, activation= 'relu'))\n",
        "model2.add(Dense(units=64, activation = 'relu'))\n",
        "model2.add(Dense(units=5, activation='softmax'))\n",
        "model2.compile(loss=keras.losses.categorical_crossentropy,optimizer='adam', metrics=['accuracy'])\n",
        "model2.fit(x=fx_train,y=fy_train, epochs=75)\n",
        "fpred3 = model2.predict_classes(fx_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "1941/1941 [==============================] - 82s 42ms/step - loss: 22.8962 - accuracy: 0.2406\n",
            "Epoch 2/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.5395 - accuracy: 0.3019\n",
            "Epoch 3/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.4873 - accuracy: 0.3627\n",
            "Epoch 4/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.3865 - accuracy: 0.4580\n",
            "Epoch 5/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.2011 - accuracy: 0.5497\n",
            "Epoch 6/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.9820 - accuracy: 0.6388\n",
            "Epoch 7/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.7421 - accuracy: 0.7367\n",
            "Epoch 8/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.5490 - accuracy: 0.7960\n",
            "Epoch 9/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.4081 - accuracy: 0.8568\n",
            "Epoch 10/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.2739 - accuracy: 0.9037\n",
            "Epoch 11/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.1991 - accuracy: 0.9361\n",
            "Epoch 12/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.1663 - accuracy: 0.9531\n",
            "Epoch 13/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.1287 - accuracy: 0.9608\n",
            "Epoch 14/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.1298 - accuracy: 0.9619\n",
            "Epoch 15/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0687 - accuracy: 0.9794\n",
            "Epoch 16/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0651 - accuracy: 0.9809\n",
            "Epoch 17/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0602 - accuracy: 0.9830\n",
            "Epoch 18/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0539 - accuracy: 0.9882\n",
            "Epoch 19/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0339 - accuracy: 0.9882\n",
            "Epoch 20/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0324 - accuracy: 0.9887\n",
            "Epoch 21/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0604 - accuracy: 0.9856\n",
            "Epoch 22/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0459 - accuracy: 0.9887\n",
            "Epoch 23/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0127 - accuracy: 0.9969\n",
            "Epoch 24/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0243 - accuracy: 0.9938\n",
            "Epoch 25/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0654 - accuracy: 0.9897\n",
            "Epoch 26/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0381 - accuracy: 0.9943\n",
            "Epoch 27/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0100 - accuracy: 0.9974\n",
            "Epoch 28/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0555 - accuracy: 0.9815\n",
            "Epoch 29/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0373 - accuracy: 0.9882\n",
            "Epoch 30/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.1140 - accuracy: 0.9753\n",
            "Epoch 31/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.1093 - accuracy: 0.9711\n",
            "Epoch 32/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 0.0598 - accuracy: 0.9830\n",
            "Epoch 33/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 0.0573 - accuracy: 0.9851\n",
            "Epoch 34/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 0.0225 - accuracy: 0.9954\n",
            "Epoch 35/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0084 - accuracy: 0.9985\n",
            "Epoch 36/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 0.0080 - accuracy: 0.9985\n",
            "Epoch 37/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 0.0021 - accuracy: 0.9995\n",
            "Epoch 38/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 3.6775e-04 - accuracy: 1.0000\n",
            "Epoch 39/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.1276e-04 - accuracy: 1.0000\n",
            "Epoch 40/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 8.7668e-05 - accuracy: 1.0000\n",
            "Epoch 41/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 7.2669e-05 - accuracy: 1.0000\n",
            "Epoch 42/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 6.1412e-05 - accuracy: 1.0000\n",
            "Epoch 43/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 5.2423e-05 - accuracy: 1.0000\n",
            "Epoch 44/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 4.6044e-05 - accuracy: 1.0000\n",
            "Epoch 45/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 4.0093e-05 - accuracy: 1.0000\n",
            "Epoch 46/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 3.5598e-05 - accuracy: 1.0000\n",
            "Epoch 47/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 3.1777e-05 - accuracy: 1.0000\n",
            "Epoch 48/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 2.8375e-05 - accuracy: 1.0000\n",
            "Epoch 49/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 2.5574e-05 - accuracy: 1.0000\n",
            "Epoch 50/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 2.3020e-05 - accuracy: 1.0000\n",
            "Epoch 51/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 2.1087e-05 - accuracy: 1.0000\n",
            "Epoch 52/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.9162e-05 - accuracy: 1.0000\n",
            "Epoch 53/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.7470e-05 - accuracy: 1.0000\n",
            "Epoch 54/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.5952e-05 - accuracy: 1.0000\n",
            "Epoch 55/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.4523e-05 - accuracy: 1.0000\n",
            "Epoch 56/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.3352e-05 - accuracy: 1.0000\n",
            "Epoch 57/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.2124e-05 - accuracy: 1.0000\n",
            "Epoch 58/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.1141e-05 - accuracy: 1.0000\n",
            "Epoch 59/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.0203e-05 - accuracy: 1.0000\n",
            "Epoch 60/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 9.1181e-06 - accuracy: 1.0000\n",
            "Epoch 61/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 8.3233e-06 - accuracy: 1.0000\n",
            "Epoch 62/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 7.2660e-06 - accuracy: 1.0000\n",
            "Epoch 63/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 6.3622e-06 - accuracy: 1.0000\n",
            "Epoch 64/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 5.2878e-06 - accuracy: 1.0000\n",
            "Epoch 65/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 4.4425e-06 - accuracy: 1.0000\n",
            "Epoch 66/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 3.6231e-06 - accuracy: 1.0000\n",
            "Epoch 67/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 3.1212e-06 - accuracy: 1.0000\n",
            "Epoch 68/75\n",
            "1941/1941 [==============================] - 67s 34ms/step - loss: 2.7726e-06 - accuracy: 1.0000\n",
            "Epoch 69/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 2.3693e-06 - accuracy: 1.0000\n",
            "Epoch 70/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 2.0058e-06 - accuracy: 1.0000\n",
            "Epoch 71/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.6289e-06 - accuracy: 1.0000\n",
            "Epoch 72/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.3770e-06 - accuracy: 1.0000\n",
            "Epoch 73/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.2220e-06 - accuracy: 1.0000\n",
            "Epoch 74/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.0835e-06 - accuracy: 1.0000\n",
            "Epoch 75/75\n",
            "1941/1941 [==============================] - 67s 35ms/step - loss: 1.0057e-06 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7YkjJYw7W-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename=\"submission_cnn_2.csv\"\n",
        "with open(filename, \"wb\") as f:\n",
        "    f.write(b'emotion\\n')\n",
        "    np.savetxt(f, fpred3.astype(int), fmt='%i', delimiter=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6I-8WQLUWBw",
        "colab_type": "code",
        "outputId": "d2b1bff5-38f7-44f4-ce31-429f618140bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_images[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(230400,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXGB2007YSNm",
        "colab_type": "text"
      },
      "source": [
        "**Tom and Jerry Emotion Detection**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3lK1AWiVKlZ",
        "colab_type": "code",
        "outputId": "28666d4a-46d9-4898-ec9d-a9de615b23ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import cv2\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D,BatchNormalization\n",
        "from keras.optimizers import RMSprop, SGD\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.regularizers import l2\n",
        "\n",
        "\n",
        "df = pd.read_csv('/content/dataset/db5fcca9-f52b-42a9-87be-26f77b6f9d97_train.csv')\n",
        "tdf = pd.read_csv('/content/final_test/c3b70bec-470d-4981-82ea-6e0693f2c8b0_test.csv')\n",
        "\n",
        "X_train = df.iloc[:,:-1]\n",
        "y_train = df.iloc[:,-1:]\n",
        "X_test = tdf\n",
        "\n",
        "train_images = []\n",
        "train_labels = []\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "for i in range(X_train.shape[0]):\n",
        "    ti_path = str(X_train.iloc[i][0])+'.jpg'\n",
        "    tpath = os.path.join('/content/dataset/ntrain/',ti_path)\n",
        "    tframe = cv2.imread(tpath)\n",
        "    timg = cv2.cvtColor(tframe, cv2.COLOR_BGR2GRAY)\n",
        "    #print('train ',timg.shape)\n",
        "    train_label = y_train.iloc[i][0]\n",
        "    train_images.append(np.asarray(timg).flatten())\n",
        "    train_labels.append(train_label)\n",
        "\n",
        "for i in range(X_test.shape[0]):\n",
        "    tei_path = str(X_test.iloc[i][0])+'.jpg'\n",
        "    tepath = os.path.join('/content/final_test/test/',tei_path)\n",
        "    teimg = cv2.imread(tepath)\n",
        "    teimg = cv2.cvtColor(teimg, cv2.COLOR_BGR2GRAY)\n",
        "    #test_label = y_test.iloc[i][0]\n",
        "    dim = (640,360)\n",
        "    teimg = cv2.resize(teimg,dim,interpolation = cv2.INTER_AREA)\n",
        "    #print('test ',teimg.shape)\n",
        "    test_images.append(np.asarray(teimg).flatten())\n",
        "    #test_labels.append(test_label)\n",
        "\n",
        "fx_train = np.array(train_images).astype('float32')\n",
        "fx_test = np.array(test_images).astype('float32')\n",
        "fy_train = to_categorical(np.array(train_labels),5)\n",
        "fx_train = fx_train.reshape(fx_train.shape[0],360,640,1)\n",
        "fx_test = fx_test.reshape(fx_test.shape[0],360,640,1)\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(filters=64, kernel_size=(4, 4), activation='relu',input_shape=(360,640,1)))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(filters=256,kernel_size=(3, 3),activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(filters=512,kernel_size=(3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Conv2D(filters=512,kernel_size=(3, 3), activation='relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(units=256, activation= 'relu'))\n",
        "model2.add(Dense(units=128, activation= 'relu'))\n",
        "model2.add(Dense(units=64, activation = 'relu'))\n",
        "model2.add(Dense(units=5, activation='softmax'))\n",
        "model2.compile(loss=keras.losses.categorical_crossentropy,optimizer='adam', metrics=['accuracy'])\n",
        "model2.fit(x=fx_train,y=fy_train,batch_size=16, epochs=75)\n",
        "fpred3 = model2.predict_classes(fx_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "1941/1941 [==============================] - 20s 10ms/step - loss: 5.8523 - accuracy: 0.2540\n",
            "Epoch 2/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 1.5501 - accuracy: 0.3256\n",
            "Epoch 3/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 1.5029 - accuracy: 0.3519\n",
            "Epoch 4/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 1.3938 - accuracy: 0.4317\n",
            "Epoch 5/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 1.1935 - accuracy: 0.5554\n",
            "Epoch 6/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 0.8664 - accuracy: 0.6909\n",
            "Epoch 7/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 0.6300 - accuracy: 0.7862\n",
            "Epoch 8/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 0.3696 - accuracy: 0.8810\n",
            "Epoch 9/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 0.2004 - accuracy: 0.9408\n",
            "Epoch 10/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 0.1169 - accuracy: 0.9696\n",
            "Epoch 11/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 0.0968 - accuracy: 0.9701\n",
            "Epoch 12/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 0.1111 - accuracy: 0.9727\n",
            "Epoch 13/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 0.0677 - accuracy: 0.9820\n",
            "Epoch 14/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 0.0767 - accuracy: 0.9794\n",
            "Epoch 15/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 0.0853 - accuracy: 0.9794\n",
            "Epoch 16/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 0.0301 - accuracy: 0.9907\n",
            "Epoch 17/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 0.0420 - accuracy: 0.9876\n",
            "Epoch 18/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 0.0411 - accuracy: 0.9861\n",
            "Epoch 19/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 0.0911 - accuracy: 0.9794\n",
            "Epoch 20/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 0.1761 - accuracy: 0.9552\n",
            "Epoch 21/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 2.7808 - accuracy: 0.6435\n",
            "Epoch 22/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 1.6213 - accuracy: 0.3457\n",
            "Epoch 23/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 1.4769 - accuracy: 0.3663\n",
            "Epoch 24/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 0.5405 - accuracy: 0.8326\n",
            "Epoch 25/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 0.1061 - accuracy: 0.9717\n",
            "Epoch 26/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 0.0721 - accuracy: 0.9845\n",
            "Epoch 27/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 0.0271 - accuracy: 0.9928\n",
            "Epoch 28/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 0.0101 - accuracy: 0.9974\n",
            "Epoch 29/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 0.0069 - accuracy: 0.9985\n",
            "Epoch 30/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 31/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 2.6031e-04 - accuracy: 1.0000\n",
            "Epoch 32/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 1.6528e-04 - accuracy: 1.0000\n",
            "Epoch 33/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 1.2187e-04 - accuracy: 1.0000\n",
            "Epoch 34/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 9.5108e-05 - accuracy: 1.0000\n",
            "Epoch 35/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 7.6602e-05 - accuracy: 1.0000\n",
            "Epoch 36/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 6.3205e-05 - accuracy: 1.0000\n",
            "Epoch 37/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 5.3175e-05 - accuracy: 1.0000\n",
            "Epoch 38/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 4.5299e-05 - accuracy: 1.0000\n",
            "Epoch 39/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 3.9006e-05 - accuracy: 1.0000\n",
            "Epoch 40/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 3.3858e-05 - accuracy: 1.0000\n",
            "Epoch 41/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 2.9589e-05 - accuracy: 1.0000\n",
            "Epoch 42/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 2.5955e-05 - accuracy: 1.0000\n",
            "Epoch 43/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 2.2892e-05 - accuracy: 1.0000\n",
            "Epoch 44/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 2.0277e-05 - accuracy: 1.0000\n",
            "Epoch 45/75\n",
            "1941/1941 [==============================] - 18s 10ms/step - loss: 1.8012e-05 - accuracy: 1.0000\n",
            "Epoch 46/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 1.6073e-05 - accuracy: 1.0000\n",
            "Epoch 47/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 1.4309e-05 - accuracy: 1.0000\n",
            "Epoch 48/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 1.2777e-05 - accuracy: 1.0000\n",
            "Epoch 49/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 1.1440e-05 - accuracy: 1.0000\n",
            "Epoch 50/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 1.0227e-05 - accuracy: 1.0000\n",
            "Epoch 51/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 9.1718e-06 - accuracy: 1.0000\n",
            "Epoch 52/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 8.2417e-06 - accuracy: 1.0000\n",
            "Epoch 53/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 7.3914e-06 - accuracy: 1.0000\n",
            "Epoch 54/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 6.6445e-06 - accuracy: 1.0000\n",
            "Epoch 55/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 5.9654e-06 - accuracy: 1.0000\n",
            "Epoch 56/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 5.3582e-06 - accuracy: 1.0000\n",
            "Epoch 57/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 4.8103e-06 - accuracy: 1.0000\n",
            "Epoch 58/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 4.3085e-06 - accuracy: 1.0000\n",
            "Epoch 59/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 3.8629e-06 - accuracy: 1.0000\n",
            "Epoch 60/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 3.4606e-06 - accuracy: 1.0000\n",
            "Epoch 61/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 3.1009e-06 - accuracy: 1.0000\n",
            "Epoch 62/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 2.7832e-06 - accuracy: 1.0000\n",
            "Epoch 63/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 2.5046e-06 - accuracy: 1.0000\n",
            "Epoch 64/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 2.2467e-06 - accuracy: 1.0000\n",
            "Epoch 65/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 2.0236e-06 - accuracy: 1.0000\n",
            "Epoch 66/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 1.8196e-06 - accuracy: 1.0000\n",
            "Epoch 67/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 1.6362e-06 - accuracy: 1.0000\n",
            "Epoch 68/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 1.4753e-06 - accuracy: 1.0000\n",
            "Epoch 69/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 1.3274e-06 - accuracy: 1.0000\n",
            "Epoch 70/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 1.1947e-06 - accuracy: 1.0000\n",
            "Epoch 71/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 1.0719e-06 - accuracy: 1.0000\n",
            "Epoch 72/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 9.6337e-07 - accuracy: 1.0000\n",
            "Epoch 73/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 8.6302e-07 - accuracy: 1.0000\n",
            "Epoch 74/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 7.7759e-07 - accuracy: 1.0000\n",
            "Epoch 75/75\n",
            "1941/1941 [==============================] - 19s 10ms/step - loss: 6.9928e-07 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7Wv1FHuY45T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename=\"submission.csv\"\n",
        "with open(filename, \"wb\") as f:\n",
        "    f.write(b'emotion\\n')\n",
        "    np.savetxt(f, fpred3.astype(int), fmt='%i', delimiter=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOomwrlkaGnK",
        "colab_type": "code",
        "outputId": "ad5848a0-6228-4517-cd00-32be359f392e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_images[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2073600,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q77cF4wHbIVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}